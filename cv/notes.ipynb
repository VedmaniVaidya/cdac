{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large-scale instance recognition (LIR):\n",
    "\n",
    "1. Large-scale instance recognition (LIR) is a computer vision task that aims to recognize a specific instance of an object in a large dataset of images\n",
    "2. This is challenging task because it requires the model to be able to identify the same object in different poses, lighting conditions, sizes, illumination conditions, and backgrounds.\n",
    "- Image retrieval, object tracking, scene understanding, and image captioning are some of the applications that can benefit from LIR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning:\n",
    "- Transfer learning is a machine learning technique where a model trained on one task is re-purposed on a second related task.\n",
    "- Ths can be done by using the pre-trained model as a feature extractor and then training a new classifier on top of the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet Dataset: 1000 classes, 1.2 million images, 150GB of data\n",
    "1. The Images are organized into hierarchical taxonomy, with each class representing a different object or scene\n",
    "2. Create by Stanford vision lab and first released in 2009\n",
    "3. Benchmark for evaluating the performance of visualt recognition algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet:\n",
    "- AlexNet consists of 8 layers: 5 convolutional layers and 3 fully connected layers\n",
    "- CNN layers use activation function ReLU and last layer uses softmax\n",
    "- AlexNet uses dropout to prevent overfitting\n",
    "- Trained on ImageNet dataset consisting of 1.4 million images and 1000 classes\n",
    "- Achieved top-5 error rate of 15.3% on ImageNet dataset in ILSVRC-2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet:\n",
    "1. Residual Connections\n",
    "2. This means that output layer of the layer is not simply the result of the convolution operation, but it also is the sum of the convolution operation and the input layer.\n",
    "3. THis allows the gradient to flow more easily through the network which makes it easier fot the network to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obejct Recognition:\n",
    "1. Object recognition is a computer vision task of identifying and localizing and classifying objects within an image or a video frame.\n",
    "2. It involves the use of computer vision  and machine learning algorithms to automatically detect and identify objects of interest in a scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCNN Model Family:\n",
    "1. The R-CNN family of methods refere to Region-based Convolutional Neural Networks, developed by Ross Girshick et al. \n",
    "2. This includes the techniques of R-CNN, Fast R-CNN, and Faster R-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCNN:\n",
    "- Module 1: Region Proposal. Generate aand extract category independent region proposals e.g. bounding boxes\n",
    "- Module 2: Feature Extraction. Extract feature from each cncaditate, r.g using a deep CNN.\n",
    "- Module 3: Classification. Classify each region using class-specific linear SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster RCNN:\n",
    "- The architecture was designed to both propose and refine region proposals as part of training process, referred to as Region Proposal Network (RPN)\n",
    "- These regions are then used in conjunction with the Fast R-CNN architecture to classify the object in the region and refine the bounding box coordinates, in a single model.\n",
    "- These improvements result in a faster and more accurate object detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
